{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/RugvedKatole/Learning-Single-Camera-Depth-Estimation-using-Dual-Pixels/blob/main/Dual_Pixel_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Dual Pixel Net implementation\nLink to Paper: [Learning Single Camera Depth Estimation using Dual Pixels](https://arxiv.org/abs/1904.05822)\n","metadata":{"id":"gx1DEesygsqC"}},{"cell_type":"markdown","source":"Import libraries ","metadata":{"id":"M-rc-dboiYy-"}},{"cell_type":"code","source":"import keras\nimport os\nimport copy\nimport json\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom scipy.interpolate import interp2d\nimport numpy.random as random\nfrom tensorflow.keras.layers import Input, Conv2D ,Conv2DTranspose, MaxPooling2D, concatenate, Add, Dense, Dropout, Activation, Flatten, BatchNormalization, SeparableConv2D, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam","metadata":{"id":"NTmQ2lBufzOI","execution":{"iopub.status.busy":"2022-03-06T16:57:31.513809Z","iopub.execute_input":"2022-03-06T16:57:31.514647Z","iopub.status.idle":"2022-03-06T16:57:31.521847Z","shell.execute_reply.started":"2022-03-06T16:57:31.514576Z","shell.execute_reply":"2022-03-06T16:57:31.520492Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Paper uses a Unet Architecture with Residual Blocks.\nUnet Architecture consists of a Encoder Decoder Network. Encoder Downsamples given images while decoder upsamples the downsampled images.k","metadata":{"id":"yqXVbr7xij31"}},{"cell_type":"code","source":"import os\nimport sys\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\npath = \"../input/google-dual-pixel-test/test/scaled_images\"\n\nfilelist = []\n\nfor root, dirs, files in os.walk(path):\n    for file in files:\n        filelist.append(os.path.join(root, file))\n\npath1 = \"../input/google-dual-pixel-test/test/merged_depth\"\nfilelist1 = []\nfor root, dirs, files in os.walk(path1):\n    for file in files:\n        filelist1.append(os.path.join(root, file))\n\nfilelist.sort()\nfilelist1.sort()\ndata = {\"image\": [x for x in filelist if x.endswith(\".jpg\")],\n       \"depth\": [x for x in filelist1 if x.endswith(\".png\")]}\ndf = pd.DataFrame(data)\n# print(df.iloc[:,1])\ndf = df.sample(frac=1, random_state=42)\n\n\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, data, batch_size=2, dim=[1008, 756], n_channels=3, shuffle=True):\n        \"\"\"\n        Initialization\n        \"\"\"\n        self.data = data\n        self.indices = self.data.index.tolist()\n        self.dim = dim\n        self.n_channels = n_channels\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.min_depth = 0.1\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.ceil(len(self.data) / self.batch_size))\n\n    def __getitem__(self, index):\n        if (index + 1) * self.batch_size > len(self.indices):\n            self.batch_size = len(self.indices) - index * self.batch_size\n        # Generate one batch of data\n        # Generate indices of the batch\n        index = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n        # Find list of IDs\n        batch = [self.indices[k] for k in index]\n        x, y = self.data_generation(batch)\n\n        return x, y\n\n    def on_epoch_end(self):\n\n        \"\"\"\n        Updates indexes after each epoch\n        \"\"\"\n        self.index = np.arange(len(self.indices))\n        if self.shuffle == True:\n            np.random.shuffle(self.index)\n\n    def load(self, image_path, depth_map):\n        \"\"\"Load input and target image.\"\"\"\n\n        image_ = cv2.imread(image_path)\n        image_ = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)\n#         image_ = cv2.resize(image_, self.dim)\n        image_ = tf.image.convert_image_dtype(image_, tf.float32)\n\n        depth_map = cv2.imread(depth_map)\n        depth_map = cv2.cvtColor(depth_map, cv2.COLOR_BGR2RGB)\n        depth_map = cv2.resize(depth_map, (378,504))\n        depth_map = tf.image.convert_image_dtype(depth_map, tf.float32)\n#         print(\"depth\",depth_map.shape)\n#         print(\"image\",image_.shape)\n        \n\n#         mask = np.load(mask)\n#         mask = mask > 0\n\n#         max_depth = min(300, np.percentile(depth_map, 99))\n#         depth_map = np.clip(depth_map, self.min_depth, max_depth)\n#         depth_map = np.log(depth_map, where=mask)\n\n#         depth_map = np.ma.masked_where(~mask, depth_map)\n\n#         depth_map = np.clip(depth_map, 0.1, np.log(max_depth))\n#         depth_map = cv2.resize(depth_map, self.dim)\n#         depth_map = np.expand_dims(depth_map, axis=2)\n#         depth_map = tf.image.convert_image_dtype(depth_map, tf.float32)\n        return image_, depth_map\n\n    def data_generation(self, batch):\n\n        x = np.empty((self.batch_size, 1008,756, self.n_channels))\n        y = np.empty((self.batch_size, 504,378, self.n_channels))\n#         print(x.shape)\n#         print(y.shape)\n        for i, batch_id in enumerate(batch):\n            x[i,], y[i,] = self.load(\n                self.data[\"image\"][batch_id],\n                self.data[\"depth\"][batch_id])\n\n        return x, y\n\n    \ntrain_loader = DataGenerator(data=df[:2736].reset_index(drop=\"true\"))\nvalidation_loader = DataGenerator(data=df[2736:].reset_index(drop=\"true\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-06T17:01:23.933355Z","iopub.execute_input":"2022-03-06T17:01:23.933631Z","iopub.status.idle":"2022-03-06T17:01:24.739517Z","shell.execute_reply.started":"2022-03-06T17:01:23.933583Z","shell.execute_reply":"2022-03-06T17:01:24.738780Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Encoder block A\ndef EncoderA(inputs=None, i_filters=32, o=32, s=2, max_pooling=True):\n    \"\"\"\n    Convolutional downsampling block\n    \n    Arguments:\n        inputs -- Input tensor\n        n_filters -- Number of filters for the convolutional layers \n        dropout_prob -- Dropout probability\n        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n    Returns: \n        next_layer, skip_connection --  Next layer and skip connection outputs\n    \"\"\"\n    # first Layer of Encoder Block\n    #Note E_a(i,o,s) == E(i,o,s)\n    conv = BatchNormalization()(inputs)\n\n    conv = Conv2D(i_filters, # Number of filters i.e i in paper (E(i,o,s))\n                  (3,3),   # 3x3 Kernel size   \n                  padding='same',\n                  strides=(s,s))(conv)    # s from E(i,o,s)\n    \n    conv = LeakyReLU(alpha=0.05)(conv)\n                \n    # Second Layer of Encoder Block Is a Depthwise Separable Convolution layer with 3x3 kernel\n    conv = BatchNormalization()(conv)\n    conv = SeparableConv2D(i_filters,(3,3),\n                            padding = 'same')(conv)\n    conv = LeakyReLU(alpha=0.05)(conv)\n\n    # Third layer of Encoder Block is 1x1 convolution Layer with o filters from E(i,o,s)\n    conv = BatchNormalization()(conv)\n    conv = Conv2D(o,(1,1), padding = 'same')(conv)\n    conv = LeakyReLU(alpha=0.05)(conv)\n\n    next_layer = BatchNormalization()(inputs)\n    next_layer = SeparableConv2D(o,(3,3),\n                            padding = 'same')(next_layer)\n    next_layer = LeakyReLU(alpha=0.05)(next_layer)\n    next_layer = MaxPooling2D(pool_size=(s,s), strides=(s,s),padding='same')(next_layer)\n    next_layer = Add()([conv,next_layer])\n        \n    skip_connection = conv\n    \n    return next_layer, skip_connection","metadata":{"id":"qUWWX_zsi6AZ","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-03-06T17:01:24.741823Z","iopub.execute_input":"2022-03-06T17:01:24.742313Z","iopub.status.idle":"2022-03-06T17:01:24.751849Z","shell.execute_reply.started":"2022-03-06T17:01:24.742275Z","shell.execute_reply":"2022-03-06T17:01:24.751132Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Encoder Block B\ndef EncoderB(inputs=None, o=32, s=2, max_pooling=True):\n    \"\"\"\n    Convolutional downsampling block\n    \n    Arguments:\n        inputs -- Input tensor\n        n_filters -- Number of filters for the convolutional layers \n        dropout_prob -- Dropout probability\n        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n    Returns: \n        next_layer, skip_connection --  Next layer and skip connection outputs\n    \"\"\"\n    # first Layer of Encoder Block\n    conv = BatchNormalization()(inputs)\n    conv = Conv2D(o, # Number of filters i.e o in paper (E_b(o,s))\n                  (7,7),   # 3x3 Kernel size   \n                  padding='same',\n                  kernel_initializer='he_normal',\n                  strides=(s,s))(conv)    # s from E(o,s)\n    conv = LeakyReLU(alpha=0.05)(conv)\n\n    # the output of conv is added to max pooled input images\n    Pooled_input = MaxPooling2D(pool_size=(s,s), strides=(s,s))(inputs)\n    next_layer = concatenate([conv,Pooled_input],axis = 3)\n    skip_connection = conv\n    \n    return next_layer, skip_connection","metadata":{"id":"0N3NiIGdo4H2","_kg_hide-input":false,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-03-06T17:01:24.994917Z","iopub.execute_input":"2022-03-06T17:01:24.995109Z","iopub.status.idle":"2022-03-06T17:01:25.001555Z","shell.execute_reply.started":"2022-03-06T17:01:24.995085Z","shell.execute_reply":"2022-03-06T17:01:25.000653Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Now we create a Decoder block for our Network","metadata":{"id":"enBcGi65oSIt"}},{"cell_type":"code","source":"# Decoder Block\ndef Decoder(expansive_input, contractive_input, i_filters = 32, o = 32):\n    \"\"\"\n    Convolutional upsampling block\n    \n    Arguments:\n        expansive_input -- Input tensor from previous layer\n        contractive_input -- Input tensor from previous skip layer\n        i_filters -- Number of filters for the convolutional layers (o from (D(i,o)))\n    Returns: \n        conv -- Tensor output\n    \"\"\"\n    # first layer of decoder block i.e transpose conv to previous layer\n    up = BatchNormalization()(expansive_input)\n    up = Conv2DTranspose(\n                i_filters,    # number of filters\n                 (4,4),    # Kernel size\n                 strides=(2,2),\n                 padding='same')(up)\n    up = LeakyReLU(alpha=0.05)(up)\n    \n    \n    # second layer of decoder block i.e 3x3 depth seperable conv \n    up = BatchNormalization()(up)\n    up = SeparableConv2D(i_filters,(3,3),\n                            padding = 'same')(up)\n    up = LeakyReLU(alpha=0.05)(up)\n\n    # Third layer of Decoder Block i.e 1x1 conv with i filters\n    up = BatchNormalization()(up)\n    up = Conv2D(i_filters,(1,1), padding = 'same')(up)\n    up = LeakyReLU(alpha=0.05)(up)\n\n    #fourth layer of Decoder block i.e 3x3 \n    up = BatchNormalization()(up)\n    up = SeparableConv2D(i_filters,(3,3),strides=(2,2),padding = 'same')(up)\n    up = LeakyReLU(alpha=0.05)(up)\n\n    # fifth layer \n    up = BatchNormalization()(up)\n    contractive_input = SeparableConv2D(i_filters,(3,3),\n                            padding = 'same')(contractive_input)\n\n    # BC kitne layers hai\n    next_layer = Add()([up,contractive_input])\n    next_layer = LeakyReLU(alpha=0.05)(next_layer)\n    #Finally the final layer\n    next_layer = BatchNormalization()(next_layer)\n    next_layer = Conv2D(o,(1,1), padding = 'same')(next_layer)\n    next_layer = LeakyReLU(alpha=0.05)(next_layer)\n\n    return next_layer","metadata":{"id":"Dvyn20QtobZ7","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-03-06T17:01:25.661847Z","iopub.execute_input":"2022-03-06T17:01:25.662312Z","iopub.status.idle":"2022-03-06T17:01:25.672161Z","shell.execute_reply.started":"2022-03-06T17:01:25.662279Z","shell.execute_reply":"2022-03-06T17:01:25.671287Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"Now we have completed the require Encoder Decoder blocks with now create our model architecture","metadata":{"id":"PdBP0b2PoSHL"}},{"cell_type":"code","source":"def Unet_model(input_size=(1024,1024,1)):\n  \"\"\"\n    Unet model\n    \n    Arguments:\n        input_size -- Input shape\n    Returns: \n        model -- tf.keras.Model\n    \"\"\"\n    #Encoding\n  inputs = Input(input_size)\n  Block1E_b = EncoderB(inputs,8,2)\n  Block1E_a = EncoderA(Block1E_b[0],11,11,1)  # E^1_a\n\n  Block2E_a = EncoderA(Block1E_b[0],16,32,2)  \n  Block2E_a = EncoderA(Block1E_b[0],16,32,1)\n  Block2E_a = EncoderA(Block1E_b[0],16,32,1) # E^2_a\n\n  Block3E_a = EncoderA(Block2E_a[0],16,64,2) \n  Block3E_a = EncoderA(Block2E_a[0],16,64,1) \n  Block3E_a = EncoderA(Block2E_a[0],16,64,1) #E^3_a\n  \n  Block4E_a = EncoderA(Block3E_a[0],32,128,2)\n  Block4E_a = EncoderA(Block3E_a[0],32,128,1)\n  Block4E_a = EncoderA(Block3E_a[0],32,128,1) #E^4_a\n\n  Block5E_a = EncoderA(Block4E_a[0],32,128,2)\n  Block5E_a = EncoderA(Block4E_a[0],32.128,1)\n  Block5E_a = EncoderA(Block4E_a[0],32,128,1) \n\n  #Decoding\n\n  Block4D = Decoder(Block5E_a[0],Block4E_a[1],32,128) #D^4\n  \n  Block3D = Decoder(Block4D,Block3E_a[1],16,64) #D^4\n\n  Block2D = Decoder(Block3D,Block2E_a[1],16,32) #D^4\n\n  Block1D = Decoder(Block2D,Block1E_a[1],8,3) #D^4\n\n  #Creating model\n  model = tf.keras.Model(inputs=inputs, outputs=Block1D)\n\n  return model\n\n\n\n","metadata":{"id":"Tu2zvERDwddA","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-03-06T17:01:26.332388Z","iopub.execute_input":"2022-03-06T17:01:26.332901Z","iopub.status.idle":"2022-03-06T17:01:26.344012Z","shell.execute_reply.started":"2022-03-06T17:01:26.332864Z","shell.execute_reply":"2022-03-06T17:01:26.343292Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model=Unet_model((1008,756,3))\nmodel.compile(optimizer= Adam(beta_2 = 0.9),loss='mean_squared_error',metrics=['mse'])\nmodel.summary()","metadata":{"id":"pyHSWCBK5jC-","outputId":"9867d418-c40c-432a-c092-914d990e252b","execution":{"iopub.status.busy":"2022-03-06T17:01:27.098508Z","iopub.execute_input":"2022-03-06T17:01:27.098913Z","iopub.status.idle":"2022-03-06T17:01:28.492846Z","shell.execute_reply.started":"2022-03-06T17:01:27.098871Z","shell.execute_reply":"2022-03-06T17:01:28.492150Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Model: \"model_6\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_7 (InputLayer)            [(None, 1008, 756, 3 0                                            \n__________________________________________________________________________________________________\nbatch_normalization_462 (BatchN (None, 1008, 756, 3) 12          input_7[0][0]                    \n__________________________________________________________________________________________________\nconv2d_210 (Conv2D)             (None, 504, 378, 8)  1184        batch_normalization_462[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_462 (LeakyReLU)     (None, 504, 378, 8)  0           conv2d_210[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_84 (MaxPooling2D) (None, 504, 378, 3)  0           input_7[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 504, 378, 11) 0           leaky_re_lu_462[0][0]            \n                                                                 max_pooling2d_84[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_475 (BatchN (None, 504, 378, 11) 44          concatenate_6[0][0]              \n__________________________________________________________________________________________________\nconv2d_217 (Conv2D)             (None, 504, 378, 16) 1600        batch_normalization_475[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_475 (LeakyReLU)     (None, 504, 378, 16) 0           conv2d_217[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_476 (BatchN (None, 504, 378, 16) 64          leaky_re_lu_475[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_234 (Separable (None, 504, 378, 16) 416         batch_normalization_476[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_476 (LeakyReLU)     (None, 504, 378, 16) 0           separable_conv2d_234[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_478 (BatchN (None, 504, 378, 11) 44          concatenate_6[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_477 (BatchN (None, 504, 378, 16) 64          leaky_re_lu_476[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_235 (Separable (None, 504, 378, 32) 483         batch_normalization_478[0][0]    \n__________________________________________________________________________________________________\nconv2d_218 (Conv2D)             (None, 504, 378, 32) 544         batch_normalization_477[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_478 (LeakyReLU)     (None, 504, 378, 32) 0           separable_conv2d_235[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_477 (LeakyReLU)     (None, 504, 378, 32) 0           conv2d_218[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_88 (MaxPooling2D) (None, 504, 378, 32) 0           leaky_re_lu_478[0][0]            \n__________________________________________________________________________________________________\nadd_105 (Add)                   (None, 504, 378, 32) 0           leaky_re_lu_477[0][0]            \n                                                                 max_pooling2d_88[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_487 (BatchN (None, 504, 378, 32) 128         add_105[0][0]                    \n__________________________________________________________________________________________________\nconv2d_223 (Conv2D)             (None, 504, 378, 16) 4624        batch_normalization_487[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_487 (LeakyReLU)     (None, 504, 378, 16) 0           conv2d_223[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_488 (BatchN (None, 504, 378, 16) 64          leaky_re_lu_487[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_240 (Separable (None, 504, 378, 16) 416         batch_normalization_488[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_488 (LeakyReLU)     (None, 504, 378, 16) 0           separable_conv2d_240[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_490 (BatchN (None, 504, 378, 32) 128         add_105[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_489 (BatchN (None, 504, 378, 16) 64          leaky_re_lu_488[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_241 (Separable (None, 504, 378, 64) 2400        batch_normalization_490[0][0]    \n__________________________________________________________________________________________________\nconv2d_224 (Conv2D)             (None, 504, 378, 64) 1088        batch_normalization_489[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_490 (LeakyReLU)     (None, 504, 378, 64) 0           separable_conv2d_241[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_489 (LeakyReLU)     (None, 504, 378, 64) 0           conv2d_224[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_91 (MaxPooling2D) (None, 504, 378, 64) 0           leaky_re_lu_490[0][0]            \n__________________________________________________________________________________________________\nadd_108 (Add)                   (None, 504, 378, 64) 0           leaky_re_lu_489[0][0]            \n                                                                 max_pooling2d_91[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_499 (BatchN (None, 504, 378, 64) 256         add_108[0][0]                    \n__________________________________________________________________________________________________\nconv2d_229 (Conv2D)             (None, 504, 378, 32) 18464       batch_normalization_499[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_499 (LeakyReLU)     (None, 504, 378, 32) 0           conv2d_229[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_500 (BatchN (None, 504, 378, 32) 128         leaky_re_lu_499[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_246 (Separable (None, 504, 378, 32) 1344        batch_normalization_500[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_500 (LeakyReLU)     (None, 504, 378, 32) 0           separable_conv2d_246[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_502 (BatchN (None, 504, 378, 64) 256         add_108[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_501 (BatchN (None, 504, 378, 32) 128         leaky_re_lu_500[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_247 (Separable (None, 504, 378, 128 8896        batch_normalization_502[0][0]    \n__________________________________________________________________________________________________\nconv2d_230 (Conv2D)             (None, 504, 378, 128 4224        batch_normalization_501[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_502 (LeakyReLU)     (None, 504, 378, 128 0           separable_conv2d_247[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_501 (LeakyReLU)     (None, 504, 378, 128 0           conv2d_230[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_94 (MaxPooling2D) (None, 504, 378, 128 0           leaky_re_lu_502[0][0]            \n__________________________________________________________________________________________________\nadd_111 (Add)                   (None, 504, 378, 128 0           leaky_re_lu_501[0][0]            \n                                                                 max_pooling2d_94[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_511 (BatchN (None, 504, 378, 128 512         add_111[0][0]                    \n__________________________________________________________________________________________________\nconv2d_235 (Conv2D)             (None, 504, 378, 32) 36896       batch_normalization_511[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_511 (LeakyReLU)     (None, 504, 378, 32) 0           conv2d_235[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_512 (BatchN (None, 504, 378, 32) 128         leaky_re_lu_511[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_252 (Separable (None, 504, 378, 32) 1344        batch_normalization_512[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_512 (LeakyReLU)     (None, 504, 378, 32) 0           separable_conv2d_252[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_514 (BatchN (None, 504, 378, 128 512         add_111[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_513 (BatchN (None, 504, 378, 32) 128         leaky_re_lu_512[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_253 (Separable (None, 504, 378, 128 17664       batch_normalization_514[0][0]    \n__________________________________________________________________________________________________\nconv2d_236 (Conv2D)             (None, 504, 378, 128 4224        batch_normalization_513[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_514 (LeakyReLU)     (None, 504, 378, 128 0           separable_conv2d_253[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_513 (LeakyReLU)     (None, 504, 378, 128 0           conv2d_236[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_97 (MaxPooling2D) (None, 504, 378, 128 0           leaky_re_lu_514[0][0]            \n__________________________________________________________________________________________________\nadd_114 (Add)                   (None, 504, 378, 128 0           leaky_re_lu_513[0][0]            \n                                                                 max_pooling2d_97[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_515 (BatchN (None, 504, 378, 128 512         add_114[0][0]                    \n__________________________________________________________________________________________________\nconv2d_transpose_24 (Conv2DTran (None, 1008, 756, 32 65568       batch_normalization_515[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_515 (LeakyReLU)     (None, 1008, 756, 32 0           conv2d_transpose_24[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_516 (BatchN (None, 1008, 756, 32 128         leaky_re_lu_515[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_254 (Separable (None, 1008, 756, 32 1344        batch_normalization_516[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_516 (LeakyReLU)     (None, 1008, 756, 32 0           separable_conv2d_254[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_517 (BatchN (None, 1008, 756, 32 128         leaky_re_lu_516[0][0]            \n__________________________________________________________________________________________________\nconv2d_237 (Conv2D)             (None, 1008, 756, 32 1056        batch_normalization_517[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_517 (LeakyReLU)     (None, 1008, 756, 32 0           conv2d_237[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_518 (BatchN (None, 1008, 756, 32 128         leaky_re_lu_517[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_255 (Separable (None, 504, 378, 32) 1344        batch_normalization_518[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_518 (LeakyReLU)     (None, 504, 378, 32) 0           separable_conv2d_255[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_519 (BatchN (None, 504, 378, 32) 128         leaky_re_lu_518[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_256 (Separable (None, 504, 378, 32) 5280        leaky_re_lu_501[0][0]            \n__________________________________________________________________________________________________\nadd_115 (Add)                   (None, 504, 378, 32) 0           batch_normalization_519[0][0]    \n                                                                 separable_conv2d_256[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_519 (LeakyReLU)     (None, 504, 378, 32) 0           add_115[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_520 (BatchN (None, 504, 378, 32) 128         leaky_re_lu_519[0][0]            \n__________________________________________________________________________________________________\nconv2d_238 (Conv2D)             (None, 504, 378, 128 4224        batch_normalization_520[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_520 (LeakyReLU)     (None, 504, 378, 128 0           conv2d_238[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_521 (BatchN (None, 504, 378, 128 512         leaky_re_lu_520[0][0]            \n__________________________________________________________________________________________________\nconv2d_transpose_25 (Conv2DTran (None, 1008, 756, 16 32784       batch_normalization_521[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_521 (LeakyReLU)     (None, 1008, 756, 16 0           conv2d_transpose_25[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_522 (BatchN (None, 1008, 756, 16 64          leaky_re_lu_521[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_257 (Separable (None, 1008, 756, 16 416         batch_normalization_522[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_522 (LeakyReLU)     (None, 1008, 756, 16 0           separable_conv2d_257[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_523 (BatchN (None, 1008, 756, 16 64          leaky_re_lu_522[0][0]            \n__________________________________________________________________________________________________\nconv2d_239 (Conv2D)             (None, 1008, 756, 16 272         batch_normalization_523[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_523 (LeakyReLU)     (None, 1008, 756, 16 0           conv2d_239[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_524 (BatchN (None, 1008, 756, 16 64          leaky_re_lu_523[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_258 (Separable (None, 504, 378, 16) 416         batch_normalization_524[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_524 (LeakyReLU)     (None, 504, 378, 16) 0           separable_conv2d_258[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_525 (BatchN (None, 504, 378, 16) 64          leaky_re_lu_524[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_259 (Separable (None, 504, 378, 16) 1616        leaky_re_lu_489[0][0]            \n__________________________________________________________________________________________________\nadd_116 (Add)                   (None, 504, 378, 16) 0           batch_normalization_525[0][0]    \n                                                                 separable_conv2d_259[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_525 (LeakyReLU)     (None, 504, 378, 16) 0           add_116[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_526 (BatchN (None, 504, 378, 16) 64          leaky_re_lu_525[0][0]            \n__________________________________________________________________________________________________\nconv2d_240 (Conv2D)             (None, 504, 378, 64) 1088        batch_normalization_526[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_526 (LeakyReLU)     (None, 504, 378, 64) 0           conv2d_240[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_527 (BatchN (None, 504, 378, 64) 256         leaky_re_lu_526[0][0]            \n__________________________________________________________________________________________________\nconv2d_transpose_26 (Conv2DTran (None, 1008, 756, 16 16400       batch_normalization_527[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_527 (LeakyReLU)     (None, 1008, 756, 16 0           conv2d_transpose_26[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_528 (BatchN (None, 1008, 756, 16 64          leaky_re_lu_527[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_260 (Separable (None, 1008, 756, 16 416         batch_normalization_528[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_528 (LeakyReLU)     (None, 1008, 756, 16 0           separable_conv2d_260[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_529 (BatchN (None, 1008, 756, 16 64          leaky_re_lu_528[0][0]            \n__________________________________________________________________________________________________\nconv2d_241 (Conv2D)             (None, 1008, 756, 16 272         batch_normalization_529[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_529 (LeakyReLU)     (None, 1008, 756, 16 0           conv2d_241[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_530 (BatchN (None, 1008, 756, 16 64          leaky_re_lu_529[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_261 (Separable (None, 504, 378, 16) 416         batch_normalization_530[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_530 (LeakyReLU)     (None, 504, 378, 16) 0           separable_conv2d_261[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_531 (BatchN (None, 504, 378, 16) 64          leaky_re_lu_530[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_262 (Separable (None, 504, 378, 16) 816         leaky_re_lu_477[0][0]            \n__________________________________________________________________________________________________\nadd_117 (Add)                   (None, 504, 378, 16) 0           batch_normalization_531[0][0]    \n                                                                 separable_conv2d_262[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_531 (LeakyReLU)     (None, 504, 378, 16) 0           add_117[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_532 (BatchN (None, 504, 378, 16) 64          leaky_re_lu_531[0][0]            \n__________________________________________________________________________________________________\nconv2d_242 (Conv2D)             (None, 504, 378, 32) 544         batch_normalization_532[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_532 (LeakyReLU)     (None, 504, 378, 32) 0           conv2d_242[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_533 (BatchN (None, 504, 378, 32) 128         leaky_re_lu_532[0][0]            \n__________________________________________________________________________________________________\nconv2d_transpose_27 (Conv2DTran (None, 1008, 756, 8) 4104        batch_normalization_533[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_533 (LeakyReLU)     (None, 1008, 756, 8) 0           conv2d_transpose_27[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_534 (BatchN (None, 1008, 756, 8) 32          leaky_re_lu_533[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_463 (BatchN (None, 504, 378, 11) 44          concatenate_6[0][0]              \n__________________________________________________________________________________________________\nseparable_conv2d_263 (Separable (None, 1008, 756, 8) 144         batch_normalization_534[0][0]    \n__________________________________________________________________________________________________\nconv2d_211 (Conv2D)             (None, 504, 378, 11) 1100        batch_normalization_463[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_534 (LeakyReLU)     (None, 1008, 756, 8) 0           separable_conv2d_263[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_463 (LeakyReLU)     (None, 504, 378, 11) 0           conv2d_211[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_535 (BatchN (None, 1008, 756, 8) 32          leaky_re_lu_534[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_464 (BatchN (None, 504, 378, 11) 44          leaky_re_lu_463[0][0]            \n__________________________________________________________________________________________________\nconv2d_243 (Conv2D)             (None, 1008, 756, 8) 72          batch_normalization_535[0][0]    \n__________________________________________________________________________________________________\nseparable_conv2d_228 (Separable (None, 504, 378, 11) 231         batch_normalization_464[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_535 (LeakyReLU)     (None, 1008, 756, 8) 0           conv2d_243[0][0]                 \n__________________________________________________________________________________________________\nleaky_re_lu_464 (LeakyReLU)     (None, 504, 378, 11) 0           separable_conv2d_228[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_536 (BatchN (None, 1008, 756, 8) 32          leaky_re_lu_535[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_465 (BatchN (None, 504, 378, 11) 44          leaky_re_lu_464[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_264 (Separable (None, 504, 378, 8)  144         batch_normalization_536[0][0]    \n__________________________________________________________________________________________________\nconv2d_212 (Conv2D)             (None, 504, 378, 11) 132         batch_normalization_465[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_536 (LeakyReLU)     (None, 504, 378, 8)  0           separable_conv2d_264[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_465 (LeakyReLU)     (None, 504, 378, 11) 0           conv2d_212[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_537 (BatchN (None, 504, 378, 8)  32          leaky_re_lu_536[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_265 (Separable (None, 504, 378, 8)  195         leaky_re_lu_465[0][0]            \n__________________________________________________________________________________________________\nadd_118 (Add)                   (None, 504, 378, 8)  0           batch_normalization_537[0][0]    \n                                                                 separable_conv2d_265[0][0]       \n__________________________________________________________________________________________________\nleaky_re_lu_537 (LeakyReLU)     (None, 504, 378, 8)  0           add_118[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_538 (BatchN (None, 504, 378, 8)  32          leaky_re_lu_537[0][0]            \n__________________________________________________________________________________________________\nconv2d_244 (Conv2D)             (None, 504, 378, 3)  27          batch_normalization_538[0][0]    \n__________________________________________________________________________________________________\nleaky_re_lu_538 (LeakyReLU)     (None, 504, 378, 3)  0           conv2d_244[0][0]                 \n==================================================================================================\nTotal params: 251,872\nTrainable params: 249,052\nNon-trainable params: 2,820\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"with tf.device('/device:GPU:0'):\n    model.fit(train_loader,epochs=10,validation_data=validation_loader,verbose='auto')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T17:01:28.494479Z","iopub.execute_input":"2022-03-06T17:01:28.494917Z","iopub.status.idle":"2022-03-06T17:01:50.992534Z","shell.execute_reply.started":"2022-03-06T17:01:28.494870Z","shell.execute_reply":"2022-03-06T17:01:50.991476Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"(504, 378, 3)\n(504, 378, 3)\nEpoch 1/10\n(504, 378, 3)\n(504, 378, 3)\n(504, 378, 3)\n(504, 378, 3)\n   1/1368 [..............................] - ETA: 3:02:34 - loss: 0.7517 - mse: 0.7517(504, 378, 3)\n   2/1368 [..............................] - ETA: 44:08 - loss: 0.7326 - mse: 0.7326  (504, 378, 3)\n(504, 378, 3)\n   3/1368 [..............................] - ETA: 45:55 - loss: 0.6963 - mse: 0.6963(504, 378, 3)\n(504, 378, 3)\n   4/1368 [..............................] - ETA: 46:06 - loss: 0.6754 - mse: 0.6754(504, 378, 3)\n(504, 378, 3)\n   5/1368 [..............................] - ETA: 46:15 - loss: 0.6668 - mse: 0.6668(504, 378, 3)\n(504, 378, 3)\n   6/1368 [..............................] - ETA: 46:24 - loss: 0.6491 - mse: 0.6491(504, 378, 3)\n(504, 378, 3)\n   7/1368 [..............................] - ETA: 46:10 - loss: 0.6369 - mse: 0.6369(504, 378, 3)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/3482043486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"},{"name":"stdout","text":"(504, 378, 3)\n(504, 378, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}