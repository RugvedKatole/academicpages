{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d58a3e1",
   "metadata": {
    "id": "view-in-github",
    "papermill": {
     "duration": 0.020748,
     "end_time": "2022-03-07T06:05:01.948550",
     "exception": false,
     "start_time": "2022-03-07T06:05:01.927802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RugvedKatole/Learning-Single-Camera-Depth-Estimation-using-Dual-Pixels/blob/main/Dual_Pixel_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74d570",
   "metadata": {
    "id": "gx1DEesygsqC",
    "papermill": {
     "duration": 0.02012,
     "end_time": "2022-03-07T06:05:01.988626",
     "exception": false,
     "start_time": "2022-03-07T06:05:01.968506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dual Pixel Net implementation\n",
    "Link to Paper: [Learning Single Camera Depth Estimation using Dual Pixels](https://arxiv.org/abs/1904.05822)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995aaf59",
   "metadata": {
    "id": "M-rc-dboiYy-",
    "papermill": {
     "duration": 0.01251,
     "end_time": "2022-03-07T06:05:02.013789",
     "exception": false,
     "start_time": "2022-03-07T06:05:02.001279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93073f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:05:02.049972Z",
     "iopub.status.busy": "2022-03-07T06:05:02.049320Z",
     "iopub.status.idle": "2022-03-07T06:05:07.293993Z",
     "shell.execute_reply": "2022-03-07T06:05:07.294622Z",
     "shell.execute_reply.started": "2022-03-06T16:57:31.514576Z"
    },
    "id": "NTmQ2lBufzOI",
    "papermill": {
     "duration": 5.268924,
     "end_time": "2022-03-07T06:05:07.294877",
     "exception": false,
     "start_time": "2022-03-07T06:05:02.025953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy.interpolate import interp2d\n",
    "import numpy.random as random\n",
    "from tensorflow.keras.layers import Input, Conv2D ,Conv2DTranspose, MaxPooling2D, concatenate, Add, Dense, Dropout, Activation, Flatten, BatchNormalization, SeparableConv2D, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0dd6a4",
   "metadata": {
    "id": "yqXVbr7xij31",
    "papermill": {
     "duration": 0.012936,
     "end_time": "2022-03-07T06:05:07.320416",
     "exception": false,
     "start_time": "2022-03-07T06:05:07.307480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Paper uses a Unet Architecture with Residual Blocks.\n",
    "Unet Architecture consists of a Encoder Decoder Network. Encoder Downsamples given images while decoder upsamples the downsampled images.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4848bde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:05:07.365499Z",
     "iopub.status.busy": "2022-03-07T06:05:07.364828Z",
     "iopub.status.idle": "2022-03-07T06:05:14.106020Z",
     "shell.execute_reply": "2022-03-07T06:05:14.105472Z",
     "shell.execute_reply.started": "2022-03-06T17:01:23.933583Z"
    },
    "papermill": {
     "duration": 6.773344,
     "end_time": "2022-03-07T06:05:14.106148",
     "exception": false,
     "start_time": "2022-03-07T06:05:07.332804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"../input/google-dual-pixel-test/test/scaled_images\"\n",
    "\n",
    "filelist = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        filelist.append(os.path.join(root, file))\n",
    "\n",
    "path1 = \"../input/google-dual-pixel-test/test/merged_depth\"\n",
    "filelist1 = []\n",
    "for root, dirs, files in os.walk(path1):\n",
    "    for file in files:\n",
    "        filelist1.append(os.path.join(root, file))\n",
    "\n",
    "filelist.sort()\n",
    "filelist1.sort()\n",
    "data = {\"image\": [x for x in filelist if x.endswith(\".jpg\")],\n",
    "       \"depth\": [x for x in filelist1 if x.endswith(\".png\")]}\n",
    "df = pd.DataFrame(data)\n",
    "# print(df.iloc[:,1])\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, batch_size=2, dim=[1008, 756], n_channels=3, shuffle=True):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.indices = self.data.index.tolist()\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.min_depth = 0.1\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if (index + 1) * self.batch_size > len(self.indices):\n",
    "            self.batch_size = len(self.indices) - index * self.batch_size\n",
    "        # Generate one batch of data\n",
    "        # Generate indices of the batch\n",
    "        index = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        # Find list of IDs\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        x, y = self.data_generation(batch)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def load(self, image_path, depth_map):\n",
    "        \"\"\"Load input and target image.\"\"\"\n",
    "\n",
    "        image_ = cv2.imread(image_path)\n",
    "        image_ = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)\n",
    "#         image_ = cv2.resize(image_, self.dim)\n",
    "        image_ = tf.image.convert_image_dtype(image_, tf.float32)\n",
    "\n",
    "        depth_map = cv2.imread(depth_map)\n",
    "        depth_map = cv2.cvtColor(depth_map, cv2.COLOR_BGR2RGB)\n",
    "        depth_map = cv2.resize(depth_map, (378,504))\n",
    "        depth_map = tf.image.convert_image_dtype(depth_map, tf.float32)\n",
    "#         print(\"depth\",depth_map.shape)\n",
    "#         print(\"image\",image_.shape)\n",
    "        \n",
    "\n",
    "#         mask = np.load(mask)\n",
    "#         mask = mask > 0\n",
    "\n",
    "#         max_depth = min(300, np.percentile(depth_map, 99))\n",
    "#         depth_map = np.clip(depth_map, self.min_depth, max_depth)\n",
    "#         depth_map = np.log(depth_map, where=mask)\n",
    "\n",
    "#         depth_map = np.ma.masked_where(~mask, depth_map)\n",
    "\n",
    "#         depth_map = np.clip(depth_map, 0.1, np.log(max_depth))\n",
    "#         depth_map = cv2.resize(depth_map, self.dim)\n",
    "#         depth_map = np.expand_dims(depth_map, axis=2)\n",
    "#         depth_map = tf.image.convert_image_dtype(depth_map, tf.float32)\n",
    "        return image_, depth_map\n",
    "\n",
    "    def data_generation(self, batch):\n",
    "\n",
    "        x = np.empty((self.batch_size, 1008,756, self.n_channels))\n",
    "        y = np.empty((self.batch_size, 504,378, self.n_channels))\n",
    "#         print(x.shape)\n",
    "#         print(y.shape)\n",
    "        for i, batch_id in enumerate(batch):\n",
    "            x[i,], y[i,] = self.load(\n",
    "                self.data[\"image\"][batch_id],\n",
    "                self.data[\"depth\"][batch_id])\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    \n",
    "train_loader = DataGenerator(data=df[:2736].reset_index(drop=\"true\"))\n",
    "validation_loader = DataGenerator(data=df[2736:].reset_index(drop=\"true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa61d9df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:05:14.142329Z",
     "iopub.status.busy": "2022-03-07T06:05:14.141451Z",
     "iopub.status.idle": "2022-03-07T06:05:14.143640Z",
     "shell.execute_reply": "2022-03-07T06:05:14.144125Z",
     "shell.execute_reply.started": "2022-03-06T17:01:24.742275Z"
    },
    "id": "qUWWX_zsi6AZ",
    "papermill": {
     "duration": 0.025097,
     "end_time": "2022-03-07T06:05:14.144270",
     "exception": false,
     "start_time": "2022-03-07T06:05:14.119173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder block A\n",
    "def EncoderA(inputs=None, i_filters=32, o=32, s=2, max_pooling=True):\n",
    "    \"\"\"\n",
    "    Convolutional downsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        inputs -- Input tensor\n",
    "        n_filters -- Number of filters for the convolutional layers \n",
    "        dropout_prob -- Dropout probability\n",
    "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
    "    Returns: \n",
    "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
    "    \"\"\"\n",
    "    # first Layer of Encoder Block\n",
    "    #Note E_a(i,o,s) == E(i,o,s)\n",
    "    conv = BatchNormalization()(inputs)\n",
    "\n",
    "    conv = Conv2D(i_filters, # Number of filters i.e i in paper (E(i,o,s))\n",
    "                  (3,3),   # 3x3 Kernel size   \n",
    "                  padding='same',\n",
    "                  strides=(s,s))(conv)    # s from E(i,o,s)\n",
    "    \n",
    "    conv = LeakyReLU(alpha=0.05)(conv)\n",
    "                \n",
    "    # Second Layer of Encoder Block Is a Depthwise Separable Convolution layer with 3x3 kernel\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = SeparableConv2D(i_filters,(3,3),\n",
    "                            padding = 'same')(conv)\n",
    "    conv = LeakyReLU(alpha=0.05)(conv)\n",
    "\n",
    "    # Third layer of Encoder Block is 1x1 convolution Layer with o filters from E(i,o,s)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Conv2D(o,(1,1), padding = 'same')(conv)\n",
    "    conv = LeakyReLU(alpha=0.05)(conv)\n",
    "\n",
    "    next_layer = BatchNormalization()(inputs)\n",
    "    next_layer = SeparableConv2D(o,(3,3),\n",
    "                            padding = 'same')(next_layer)\n",
    "    next_layer = LeakyReLU(alpha=0.05)(next_layer)\n",
    "    next_layer = MaxPooling2D(pool_size=(s,s), strides=(s,s),padding='same')(next_layer)\n",
    "    next_layer = Add()([conv,next_layer])\n",
    "        \n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff19f535",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:05:14.176295Z",
     "iopub.status.busy": "2022-03-07T06:05:14.175550Z",
     "iopub.status.idle": "2022-03-07T06:05:14.177918Z",
     "shell.execute_reply": "2022-03-07T06:05:14.177476Z",
     "shell.execute_reply.started": "2022-03-06T17:01:24.995085Z"
    },
    "id": "0N3NiIGdo4H2",
    "papermill": {
     "duration": 0.021087,
     "end_time": "2022-03-07T06:05:14.178022",
     "exception": false,
     "start_time": "2022-03-07T06:05:14.156935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder Block B\n",
    "def EncoderB(inputs=None, o=32, s=2, max_pooling=True):\n",
    "    \"\"\"\n",
    "    Convolutional downsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        inputs -- Input tensor\n",
    "        n_filters -- Number of filters for the convolutional layers \n",
    "        dropout_prob -- Dropout probability\n",
    "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
    "    Returns: \n",
    "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
    "    \"\"\"\n",
    "    # first Layer of Encoder Block\n",
    "    conv = BatchNormalization()(inputs)\n",
    "    conv = Conv2D(o, # Number of filters i.e o in paper (E_b(o,s))\n",
    "                  (7,7),   # 3x3 Kernel size   \n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  strides=(s,s))(conv)    # s from E(o,s)\n",
    "    conv = LeakyReLU(alpha=0.05)(conv)\n",
    "\n",
    "    # the output of conv is added to max pooled input images\n",
    "    Pooled_input = MaxPooling2D(pool_size=(s,s), strides=(s,s))(inputs)\n",
    "    next_layer = concatenate([conv,Pooled_input],axis = 3)\n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e62e9e",
   "metadata": {
    "id": "enBcGi65oSIt",
    "papermill": {
     "duration": 0.012292,
     "end_time": "2022-03-07T06:05:14.202744",
     "exception": false,
     "start_time": "2022-03-07T06:05:14.190452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we create a Decoder block for our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5488974a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:05:14.238851Z",
     "iopub.status.busy": "2022-03-07T06:05:14.237960Z",
     "iopub.status.idle": "2022-03-07T06:05:14.239697Z",
     "shell.execute_reply": "2022-03-07T06:05:14.240191Z",
     "shell.execute_reply.started": "2022-03-06T17:01:25.662279Z"
    },
    "id": "Dvyn20QtobZ7",
    "papermill": {
     "duration": 0.025089,
     "end_time": "2022-03-07T06:05:14.240306",
     "exception": false,
     "start_time": "2022-03-07T06:05:14.215217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decoder Block\n",
    "def Decoder(expansive_input, contractive_input, i_filters = 32, o = 32):\n",
    "    \"\"\"\n",
    "    Convolutional upsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        expansive_input -- Input tensor from previous layer\n",
    "        contractive_input -- Input tensor from previous skip layer\n",
    "        i_filters -- Number of filters for the convolutional layers (o from (D(i,o)))\n",
    "    Returns: \n",
    "        conv -- Tensor output\n",
    "    \"\"\"\n",
    "    # first layer of decoder block i.e transpose conv to previous layer\n",
    "    up = BatchNormalization()(expansive_input)\n",
    "    up = Conv2DTranspose(\n",
    "                i_filters,    # number of filters\n",
    "                 (4,4),    # Kernel size\n",
    "                 strides=(2,2),\n",
    "                 padding='same')(up)\n",
    "    up = LeakyReLU(alpha=0.05)(up)\n",
    "    \n",
    "    \n",
    "    # second layer of decoder block i.e 3x3 depth seperable conv \n",
    "    up = BatchNormalization()(up)\n",
    "    up = SeparableConv2D(i_filters,(3,3),\n",
    "                            padding = 'same')(up)\n",
    "    up = LeakyReLU(alpha=0.05)(up)\n",
    "\n",
    "    # Third layer of Decoder Block i.e 1x1 conv with i filters\n",
    "    up = BatchNormalization()(up)\n",
    "    up = Conv2D(i_filters,(1,1), padding = 'same')(up)\n",
    "    up = LeakyReLU(alpha=0.05)(up)\n",
    "\n",
    "    #fourth layer of Decoder block i.e 3x3 \n",
    "    up = BatchNormalization()(up)\n",
    "    up = SeparableConv2D(i_filters,(3,3),strides=(2,2),padding = 'same')(up)\n",
    "    up = LeakyReLU(alpha=0.05)(up)\n",
    "\n",
    "    # fifth layer \n",
    "    up = BatchNormalization()(up)\n",
    "    contractive_input = SeparableConv2D(i_filters,(3,3),\n",
    "                            padding = 'same')(contractive_input)\n",
    "\n",
    "    # BC kitne layers hai\n",
    "    next_layer = Add()([up,contractive_input])\n",
    "    next_layer = LeakyReLU(alpha=0.05)(next_layer)\n",
    "    #Finally the final layer\n",
    "    next_layer = BatchNormalization()(next_layer)\n",
    "    next_layer = Conv2D(o,(1,1), padding = 'same')(next_layer)\n",
    "    next_layer = LeakyReLU(alpha=0.05)(next_layer)\n",
    "\n",
    "    return next_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b3cab",
   "metadata": {
    "id": "PdBP0b2PoSHL",
    "papermill": {
     "duration": 0.012286,
     "end_time": "2022-03-07T06:05:14.265193",
     "exception": false,
     "start_time": "2022-03-07T06:05:14.252907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we have completed the require Encoder Decoder blocks with now create our model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e03d6fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:05:14.301448Z",
     "iopub.status.busy": "2022-03-07T06:05:14.293809Z",
     "iopub.status.idle": "2022-03-07T06:05:14.303717Z",
     "shell.execute_reply": "2022-03-07T06:05:14.303290Z",
     "shell.execute_reply.started": "2022-03-06T17:01:26.332864Z"
    },
    "id": "Tu2zvERDwddA",
    "papermill": {
     "duration": 0.026335,
     "end_time": "2022-03-07T06:05:14.303824",
     "exception": false,
     "start_time": "2022-03-07T06:05:14.277489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Unet_model(input_size=(1024,1024,1)):\n",
    "  \"\"\"\n",
    "    Unet model\n",
    "    \n",
    "    Arguments:\n",
    "        input_size -- Input shape\n",
    "    Returns: \n",
    "        model -- tf.keras.Model\n",
    "    \"\"\"\n",
    "    #Encoding\n",
    "  inputs = Input(input_size)\n",
    "  Block1E_b = EncoderB(inputs,8,2)\n",
    "  Block1E_a = EncoderA(Block1E_b[0],11,11,1)  # E^1_a\n",
    "\n",
    "  Block2E_a = EncoderA(Block1E_b[0],16,32,2)  \n",
    "  Block2E_a = EncoderA(Block1E_b[0],16,32,1)\n",
    "  Block2E_a = EncoderA(Block1E_b[0],16,32,1) # E^2_a\n",
    "\n",
    "  Block3E_a = EncoderA(Block2E_a[0],16,64,2) \n",
    "  Block3E_a = EncoderA(Block2E_a[0],16,64,1) \n",
    "  Block3E_a = EncoderA(Block2E_a[0],16,64,1) #E^3_a\n",
    "  \n",
    "  Block4E_a = EncoderA(Block3E_a[0],32,128,2)\n",
    "  Block4E_a = EncoderA(Block3E_a[0],32,128,1)\n",
    "  Block4E_a = EncoderA(Block3E_a[0],32,128,1) #E^4_a\n",
    "\n",
    "  Block5E_a = EncoderA(Block4E_a[0],32,128,2)\n",
    "  Block5E_a = EncoderA(Block4E_a[0],32.128,1)\n",
    "  Block5E_a = EncoderA(Block4E_a[0],32,128,1) \n",
    "\n",
    "  #Decoding\n",
    "\n",
    "  Block4D = Decoder(Block5E_a[0],Block4E_a[1],32,128) #D^4\n",
    "  \n",
    "  Block3D = Decoder(Block4D,Block3E_a[1],16,64) #D^4\n",
    "\n",
    "  Block2D = Decoder(Block3D,Block2E_a[1],16,32) #D^4\n",
    "\n",
    "  Block1D = Decoder(Block2D,Block1E_a[1],8,3) #D^4\n",
    "\n",
    "  #Creating model\n",
    "  model = tf.keras.Model(inputs=inputs, outputs=Block1D)\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54d9be00",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:05:14.332371Z",
     "iopub.status.busy": "2022-03-07T06:05:14.331836Z",
     "iopub.status.idle": "2022-03-07T06:05:18.172862Z",
     "shell.execute_reply": "2022-03-07T06:05:18.173361Z",
     "shell.execute_reply.started": "2022-03-06T17:01:27.098871Z"
    },
    "id": "pyHSWCBK5jC-",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "9867d418-c40c-432a-c092-914d990e252b",
    "papermill": {
     "duration": 3.857312,
     "end_time": "2022-03-07T06:05:18.173512",
     "exception": false,
     "start_time": "2022-03-07T06:05:14.316200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 06:05:14.412294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-07 06:05:14.513423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-07 06:05:14.514185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-07 06:05:14.515275: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-07 06:05:14.516233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-07 06:05:14.516882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-07 06:05:14.517486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-07 06:05:16.424665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-07 06:05:16.425478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-07 06:05:16.426111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-07 06:05:16.426686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1008, 756, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1008, 756, 3) 12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 504, 378, 8)  1184        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 504, 378, 8)  0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 504, 378, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 504, 378, 11) 0           leaky_re_lu[0][0]                \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 504, 378, 11) 44          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 504, 378, 16) 1600        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 504, 378, 16) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 504, 378, 16) 64          leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 504, 378, 16) 416         batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 504, 378, 16) 0           separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 504, 378, 11) 44          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 504, 378, 16) 64          leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 504, 378, 32) 483         batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 504, 378, 32) 544         batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 504, 378, 32) 0           separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 504, 378, 32) 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 504, 378, 32) 0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 504, 378, 32) 0           leaky_re_lu_15[0][0]             \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 504, 378, 32) 128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 504, 378, 16) 4624        batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 504, 378, 16) 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 504, 378, 16) 64          leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 504, 378, 16) 416         batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 504, 378, 16) 0           separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 504, 378, 32) 128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 504, 378, 16) 64          leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 504, 378, 64) 2400        batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 504, 378, 64) 1088        batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 504, 378, 64) 0           separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 504, 378, 64) 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 504, 378, 64) 0           leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 504, 378, 64) 0           leaky_re_lu_27[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 504, 378, 64) 256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 504, 378, 32) 18464       batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 504, 378, 32) 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 504, 378, 32) 128         leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 504, 378, 32) 1344        batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 504, 378, 32) 0           separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 504, 378, 64) 256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 504, 378, 32) 128         leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 504, 378, 128 8896        batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 504, 378, 128 4224        batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 504, 378, 128 0           separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 504, 378, 128 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 504, 378, 128 0           leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 504, 378, 128 0           leaky_re_lu_39[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 504, 378, 128 512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 504, 378, 32) 36896       batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 504, 378, 32) 0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 504, 378, 32) 128         leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 504, 378, 32) 1344        batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 504, 378, 32) 0           separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 504, 378, 128 512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 504, 378, 32) 128         leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 504, 378, 128 17664       batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 504, 378, 128 4224        batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 504, 378, 128 0           separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 504, 378, 128 0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 504, 378, 128 0           leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 504, 378, 128 0           leaky_re_lu_51[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 504, 378, 128 512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 1008, 756, 32 65568       batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 1008, 756, 32 0           conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1008, 756, 32 128         leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 1008, 756, 32 1344        batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 1008, 756, 32 0           separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1008, 756, 32 128         leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 1008, 756, 32 1056        batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 1008, 756, 32 0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1008, 756, 32 128         leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, 504, 378, 32) 1344        batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, 504, 378, 32) 0           separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 504, 378, 32) 128         leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, 504, 378, 32) 5280        leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 504, 378, 32) 0           batch_normalization_57[0][0]     \n",
      "                                                                 separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, 504, 378, 32) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 504, 378, 32) 128         leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 504, 378, 128 4224        batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, 504, 378, 128 0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 504, 378, 128 512         leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 1008, 756, 16 32784       batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 1008, 756, 16 0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1008, 756, 16 64          leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, 1008, 756, 16 416         batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, 1008, 756, 16 0           separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1008, 756, 16 64          leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 1008, 756, 16 272         batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, 1008, 756, 16 0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1008, 756, 16 64          leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_30 (SeparableC (None, 504, 378, 16) 416         batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, 504, 378, 16) 0           separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 504, 378, 16) 64          leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_31 (SeparableC (None, 504, 378, 16) 1616        leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 504, 378, 16) 0           batch_normalization_63[0][0]     \n",
      "                                                                 separable_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 504, 378, 16) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 504, 378, 16) 64          leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 504, 378, 64) 1088        batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 504, 378, 64) 0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 504, 378, 64) 256         leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 1008, 756, 16 16400       batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 1008, 756, 16 0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1008, 756, 16 64          leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_32 (SeparableC (None, 1008, 756, 16 416         batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, 1008, 756, 16 0           separable_conv2d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1008, 756, 16 64          leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 1008, 756, 16 272         batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 1008, 756, 16 0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1008, 756, 16 64          leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_33 (SeparableC (None, 504, 378, 16) 416         batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, 504, 378, 16) 0           separable_conv2d_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 504, 378, 16) 64          leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_34 (SeparableC (None, 504, 378, 16) 816         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 504, 378, 16) 0           batch_normalization_69[0][0]     \n",
      "                                                                 separable_conv2d_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, 504, 378, 16) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 504, 378, 16) 64          leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 504, 378, 32) 544         batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, 504, 378, 32) 0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 504, 378, 32) 128         leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 1008, 756, 8) 4104        batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, 1008, 756, 8) 0           conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1008, 756, 8) 32          leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 504, 378, 11) 44          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_35 (SeparableC (None, 1008, 756, 8) 144         batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 504, 378, 11) 1100        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, 1008, 756, 8) 0           separable_conv2d_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 504, 378, 11) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1008, 756, 8) 32          leaky_re_lu_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 504, 378, 11) 44          leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 1008, 756, 8) 72          batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 504, 378, 11) 231         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)      (None, 1008, 756, 8) 0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 504, 378, 11) 0           separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1008, 756, 8) 32          leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 504, 378, 11) 44          leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_36 (SeparableC (None, 504, 378, 8)  144         batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 504, 378, 11) 132         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)      (None, 504, 378, 8)  0           separable_conv2d_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 504, 378, 11) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 504, 378, 8)  32          leaky_re_lu_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_37 (SeparableC (None, 504, 378, 8)  195         leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 504, 378, 8)  0           batch_normalization_75[0][0]     \n",
      "                                                                 separable_conv2d_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)      (None, 504, 378, 8)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 504, 378, 8)  32          leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 504, 378, 3)  27          batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)      (None, 504, 378, 3)  0           conv2d_34[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 251,872\n",
      "Trainable params: 249,052\n",
      "Non-trainable params: 2,820\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Unet_model((1008,756,3))\n",
    "model.compile(optimizer= Adam(beta_2 = 0.9),loss='mean_squared_error',metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c37455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:05:18.206074Z",
     "iopub.status.busy": "2022-03-07T06:05:18.205411Z",
     "iopub.status.idle": "2022-03-07T06:05:18.207546Z",
     "shell.execute_reply": "2022-03-07T06:05:18.207901Z"
    },
    "papermill": {
     "duration": 0.020256,
     "end_time": "2022-03-07T06:05:18.208039",
     "exception": false,
     "start_time": "2022-03-07T06:05:18.187783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39581b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:05:18.241625Z",
     "iopub.status.busy": "2022-03-07T06:05:18.240797Z",
     "iopub.status.idle": "2022-03-07T14:05:56.442513Z",
     "shell.execute_reply": "2022-03-07T14:05:56.442982Z",
     "shell.execute_reply.started": "2022-03-06T17:01:28.49487Z"
    },
    "papermill": {
     "duration": 28838.22145,
     "end_time": "2022-03-07T14:05:56.443183",
     "exception": false,
     "start_time": "2022-03-07T06:05:18.221733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 06:05:18.475541: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 06:05:23.483768: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368/1368 [==============================] - 2915s 2s/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 2/10\n",
      "1368/1368 [==============================] - 2868s 2s/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 3/10\n",
      "1368/1368 [==============================] - 2873s 2s/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 4/10\n",
      "1368/1368 [==============================] - 2859s 2s/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 5/10\n",
      "1368/1368 [==============================] - 2871s 2s/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 6/10\n",
      "1368/1368 [==============================] - 2863s 2s/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 7/10\n",
      "1368/1368 [==============================] - 2882s 2s/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 8/10\n",
      "1368/1368 [==============================] - 2868s 2s/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 9/10\n",
      "1368/1368 [==============================] - 2855s 2s/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 10/10\n",
      "1368/1368 [==============================] - 2867s 2s/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0307 - val_mse: 0.0307\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit(train_loader,epochs=10,validation_data=validation_loader,verbose='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad24dc2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T14:06:05.661765Z",
     "iopub.status.busy": "2022-03-07T14:06:05.655807Z",
     "iopub.status.idle": "2022-03-07T14:06:06.155535Z",
     "shell.execute_reply": "2022-03-07T14:06:06.155979Z"
    },
    "papermill": {
     "duration": 4.819061,
     "end_time": "2022-03-07T14:06:06.156164",
     "exception": false,
     "start_time": "2022-03-07T14:06:01.337103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28879.847719,
   "end_time": "2022-03-07T14:06:13.773179",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-07T06:04:53.925460",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
